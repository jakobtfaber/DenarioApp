{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denario Manuscript Review and Completion Workflow\n",
    "\n",
    "This notebook demonstrates how to use Denario for comprehensive manuscript review, including:\n",
    "\n",
    "## Key Features:\n",
    "- **LaTeX to JSONL Conversion** - Convert manuscripts to structured format using ragbook\n",
    "- **Section Completeness Analysis** - Identify incomplete sections with semantic understanding\n",
    "- **Rich Structured Analysis** - Process prose, equations, figures, and tables separately\n",
    "- **Citation Integration** - Add relevant in-text citations with context\n",
    "- **Mathematical Verification** - Check calculations and derivations with normalized math\n",
    "- **Simulation Validation** - Verify computational results\n",
    "- **Content Enhancement** - Improve flow and completeness\n",
    "- **Referee Response** - Address reviewer comments systematically\n",
    "\n",
    "## Workflow:\n",
    "1. **Upload your manuscript** (LaTeX, Word, or Markdown)\n",
    "2. **Convert LaTeX to JSONL** (Recommended) - Use ragbook for rich structured analysis\n",
    "3. **Upload referee report** (if available) for systematic comment parsing\n",
    "4. **Analyze completeness** and identify gaps using structured data\n",
    "5. **Generate responses** to referee comments with priority handling\n",
    "6. **Generate missing content** with proper citations\n",
    "7. **Verify all mathematical derivations** and equations\n",
    "8. **Validate simulations and calculations**\n",
    "9. **Generate revised manuscript** with enhanced structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Manuscript Review System Initialized\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for manuscript review\n",
    "from denario import Denario, Journal, models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown, HTML\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"üìö Manuscript Review System Initialized\")\n",
    "print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Manuscript Upload and Analysis\n",
    "\n",
    "### Option A: Direct Upload (LaTeX, Word, Markdown)\n",
    "### Option B: Convert to JSONL with ragbook (Recommended for Rich Analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b2cf468367443b499d151779241b572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>üîÑ ragbook LaTeX to JSONL Conversion</h3>'), HTML(value='<p>Convert your LaTeX m‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ragbook Conversion Interface\n",
    "def create_ragbook_conversion_interface():\n",
    "    \"\"\"Create interactive interface for ragbook conversion\"\"\"\n",
    "    \n",
    "    # LaTeX file upload widget\n",
    "    tex_upload = widgets.FileUpload(\n",
    "        accept='.tex',\n",
    "        multiple=False,\n",
    "        description='Upload LaTeX File',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Source ID input\n",
    "    source_id_input = widgets.Text(\n",
    "        value='manuscript',\n",
    "        placeholder='Enter source ID (e.g., my-paper-v1)',\n",
    "        description='Source ID:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Convert button\n",
    "    convert_button = widgets.Button(\n",
    "        description='Convert to JSONL',\n",
    "        button_style='primary',\n",
    "        icon='cogs'\n",
    "    )\n",
    "    \n",
    "    # Output area\n",
    "    conversion_output = widgets.Output()\n",
    "    \n",
    "    def on_convert_clicked(b):\n",
    "        with conversion_output:\n",
    "            conversion_output.clear_output()\n",
    "            \n",
    "            if not tex_upload.value:\n",
    "                print(\"‚ùå Please upload a LaTeX file first\")\n",
    "                return\n",
    "            \n",
    "            # Get the uploaded file\n",
    "            uploaded_file = list(tex_upload.value.values())[0]\n",
    "            file_name = uploaded_file['name']\n",
    "            \n",
    "            # Save to temporary file\n",
    "            temp_tex_path = f\"/tmp/{file_name}\"\n",
    "            with open(temp_tex_path, 'wb') as f:\n",
    "                f.write(uploaded_file['content'])\n",
    "            \n",
    "            print(f\"üìÑ Processing LaTeX file: {file_name}\")\n",
    "            print(\"=\" * 50)\n",
    "            \n",
    "            # Convert to JSONL\n",
    "            source_id = source_id_input.value.strip() or 'manuscript'\n",
    "            jsonl_path = convert_manuscript_to_jsonl(temp_tex_path, source_id=source_id)\n",
    "            \n",
    "            if jsonl_path:\n",
    "                # Analyze conversion results\n",
    "                analysis = analyze_conversion_results(jsonl_path)\n",
    "                \n",
    "                if analysis:\n",
    "                    print(f\"\\n‚úÖ Conversion completed successfully!\")\n",
    "                    print(f\"üìÅ JSONL file: {jsonl_path}\")\n",
    "                    print(f\"üìä Ready for rich structured analysis\")\n",
    "                    \n",
    "                    # Store the JSONL path for later use\n",
    "                    global current_jsonl_path\n",
    "                    current_jsonl_path = jsonl_path\n",
    "                    \n",
    "                    print(f\"\\nüí° Next steps:\")\n",
    "                    print(f\"  1. Use the 'Enhanced Analysis' section below\")\n",
    "                    print(f\"  2. Upload the JSONL file for rich structured analysis\")\n",
    "                    print(f\"  3. Or use the direct analysis with the JSONL parser\")\n",
    "                else:\n",
    "                    print(\"‚ùå Failed to analyze conversion results\")\n",
    "            else:\n",
    "                print(\"‚ùå Conversion failed\")\n",
    "    \n",
    "    convert_button.on_click(on_convert_clicked)\n",
    "    \n",
    "    # Layout\n",
    "    interface = widgets.VBox([\n",
    "        widgets.HTML(\"<h3>üîÑ ragbook LaTeX to JSONL Conversion</h3>\"),\n",
    "        widgets.HTML(\"<p>Convert your LaTeX manuscript to structured JSONL format for rich analysis:</p>\"),\n",
    "        widgets.HTML(\"<ul><li>üìù Prose chunks with semantic structure</li><li>üßÆ Equations with normalized math</li><li>üìä Tables exported to CSV</li><li>üñºÔ∏è Figures with captions and metadata</li></ul>\"),\n",
    "        widgets.HBox([tex_upload, convert_button]),\n",
    "        source_id_input,\n",
    "        conversion_output\n",
    "    ])\n",
    "    \n",
    "    return interface\n",
    "\n",
    "# Create and display ragbook conversion interface\n",
    "ragbook_interface = create_ragbook_conversion_interface()\n",
    "display(ragbook_interface)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Manuscript Reviewer initialized\n",
      "Ready to analyze your manuscript!\n"
     ]
    }
   ],
   "source": [
    "# ragbook integration for LaTeX to JSONL conversion\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def convert_manuscript_to_jsonl(tex_file_path, output_dir=\"/tmp\", source_id=\"manuscript\"):\n",
    "    \"\"\"\n",
    "    Convert LaTeX manuscript to JSONL format using ragbook\n",
    "    \n",
    "    Args:\n",
    "        tex_file_path: Path to the main .tex file\n",
    "        output_dir: Directory to save the JSONL output\n",
    "        source_id: Identifier for the source document\n",
    "    \n",
    "    Returns:\n",
    "        Path to the generated JSONL file, or None if conversion failed\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ensure output directory exists\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Get the project root (directory containing the tex file)\n",
    "        project_root = os.path.dirname(os.path.abspath(tex_file_path))\n",
    "        tex_filename = os.path.basename(tex_file_path)\n",
    "        \n",
    "        # Output JSONL file path\n",
    "        jsonl_output = os.path.join(output_dir, f\"{source_id}.jsonl\")\n",
    "        \n",
    "        # ragbook command\n",
    "        cmd = [\n",
    "            sys.executable,  # Use current Python interpreter\n",
    "            \"/data/cmbagents/ragbook/convert_book.py\",\n",
    "            \"--entry\", tex_filename,\n",
    "            \"--root\", project_root,\n",
    "            \"--source-id\", source_id,\n",
    "            \"--out\", jsonl_output,\n",
    "            \"--assets-dir\", project_root,  # Look for figures in the same directory\n",
    "            \"--assets-url-prefix\", \"assets/\",\n",
    "            \"--no-ocr\"  # Disable OCR for faster processing\n",
    "        ]\n",
    "        \n",
    "        print(f\"üîÑ Converting {tex_filename} to JSONL format...\")\n",
    "        print(f\"üìÅ Project root: {project_root}\")\n",
    "        print(f\"üìÑ Output: {jsonl_output}\")\n",
    "        \n",
    "        # Run the conversion\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, cwd=project_root)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(\"‚úÖ Conversion successful!\")\n",
    "            print(f\"üìä JSONL file created: {jsonl_output}\")\n",
    "            \n",
    "            # Check if file was created and has content\n",
    "            if os.path.exists(jsonl_output) and os.path.getsize(jsonl_output) > 0:\n",
    "                return jsonl_output\n",
    "            else:\n",
    "                print(\"‚ùå JSONL file was created but is empty\")\n",
    "                return None\n",
    "        else:\n",
    "            print(f\"‚ùå Conversion failed with return code {result.returncode}\")\n",
    "            print(f\"Error output: {result.stderr}\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during conversion: {e}\")\n",
    "        return None\n",
    "\n",
    "def analyze_conversion_results(jsonl_path):\n",
    "    \"\"\"Analyze the results of ragbook conversion\"\"\"\n",
    "    try:\n",
    "        with open(jsonl_path, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        # Count different types of chunks\n",
    "        chunk_types = {}\n",
    "        total_chunks = len(lines)\n",
    "        \n",
    "        for line in lines:\n",
    "            if line.strip():\n",
    "                chunk = json.loads(line.strip())\n",
    "                chunk_type = chunk.get('type', 'unknown')\n",
    "                chunk_types[chunk_type] = chunk_types.get(chunk_type, 0) + 1\n",
    "        \n",
    "        print(f\"üìä CONVERSION ANALYSIS\")\n",
    "        print(f\"=\" * 30)\n",
    "        print(f\"Total chunks: {total_chunks}\")\n",
    "        print(f\"Chunk types:\")\n",
    "        for chunk_type, count in chunk_types.items():\n",
    "            print(f\"  ‚Ä¢ {chunk_type}: {count}\")\n",
    "        \n",
    "        return {\n",
    "            'total_chunks': total_chunks,\n",
    "            'chunk_types': chunk_types,\n",
    "            'jsonl_path': jsonl_path\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error analyzing conversion results: {e}\")\n",
    "        return None\n",
    "\n",
    "# JSONL parser for ragbook format\n",
    "class JSONLManuscriptParser:\n",
    "    \"\"\"Parse ragbook JSONL format for manuscript analysis\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.chunks = []\n",
    "        self.sections = {}\n",
    "        self.equations = []\n",
    "        self.figures = []\n",
    "        self.tables = []\n",
    "        \n",
    "    def load_jsonl(self, file_path):\n",
    "        \"\"\"Load and parse JSONL file from ragbook\"\"\"\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                for line in f:\n",
    "                    if line.strip():\n",
    "                        chunk = json.loads(line.strip())\n",
    "                        self.chunks.append(chunk)\n",
    "            \n",
    "            # Organize chunks by type\n",
    "            self._organize_chunks()\n",
    "            print(f\"‚úÖ JSONL loaded: {len(self.chunks)} chunks, {len(self.sections)} sections\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading JSONL: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def _organize_chunks(self):\n",
    "        \"\"\"Organize chunks by type and section\"\"\"\n",
    "        for chunk in self.chunks:\n",
    "            chunk_type = chunk.get('type', 'other')\n",
    "            section_path = chunk.get('section_path', [])\n",
    "            \n",
    "            # Group by section\n",
    "            section_key = ' > '.join(section_path) if section_path else 'Unknown'\n",
    "            if section_key not in self.sections:\n",
    "                self.sections[section_key] = {\n",
    "                    'prose': [],\n",
    "                    'equations': [],\n",
    "                    'figures': [],\n",
    "                    'tables': [],\n",
    "                    'other': []\n",
    "                }\n",
    "            \n",
    "            # Categorize by type\n",
    "            if chunk_type == 'prose':\n",
    "                self.sections[section_key]['prose'].append(chunk)\n",
    "            elif chunk_type == 'equation':\n",
    "                self.sections[section_key]['equations'].append(chunk)\n",
    "                self.equations.append(chunk)\n",
    "            elif chunk_type == 'figure':\n",
    "                self.sections[section_key]['figures'].append(chunk)\n",
    "                self.figures.append(chunk)\n",
    "            elif chunk_type == 'table':\n",
    "                self.sections[section_key]['tables'].append(chunk)\n",
    "                self.tables.append(chunk)\n",
    "            else:\n",
    "                self.sections[section_key]['other'].append(chunk)\n",
    "    \n",
    "    def get_section_text(self, section_name):\n",
    "        \"\"\"Get all prose text for a section\"\"\"\n",
    "        for section_key, content in self.sections.items():\n",
    "            if section_name.lower() in section_key.lower():\n",
    "                prose_chunks = content['prose']\n",
    "                return ' '.join([chunk.get('text', '') for chunk in prose_chunks])\n",
    "        return \"\"\n",
    "    \n",
    "    def get_equations_for_section(self, section_name):\n",
    "        \"\"\"Get all equations for a section\"\"\"\n",
    "        equations = []\n",
    "        for section_key, content in self.sections.items():\n",
    "            if section_name.lower() in section_key.lower():\n",
    "                for eq_chunk in content['equations']:\n",
    "                    equations.append({\n",
    "                        'tex': eq_chunk.get('equation_tex', ''),\n",
    "                        'normalized': eq_chunk.get('math_norm', ''),\n",
    "                        'number': eq_chunk.get('eq_number', ''),\n",
    "                        'text': eq_chunk.get('text', '')\n",
    "                    })\n",
    "        return equations\n",
    "    \n",
    "    def get_figures_for_section(self, section_name):\n",
    "        \"\"\"Get all figures for a section\"\"\"\n",
    "        figures = []\n",
    "        for section_key, content in self.sections.items():\n",
    "            if section_name.lower() in section_key.lower():\n",
    "                for fig_chunk in content['figures']:\n",
    "                    figures.append({\n",
    "                        'caption': fig_chunk.get('caption_tex', ''),\n",
    "                        'filename': fig_chunk.get('filename', ''),\n",
    "                        'asset_uri': fig_chunk.get('asset_uri', ''),\n",
    "                        'text': fig_chunk.get('text', '')\n",
    "                    })\n",
    "        return figures\n",
    "    \n",
    "    def get_tables_for_section(self, section_name):\n",
    "        \"\"\"Get all tables for a section\"\"\"\n",
    "        tables = []\n",
    "        for section_key, content in self.sections.items():\n",
    "            if section_name.lower() in section_key.lower():\n",
    "                for table_chunk in content['tables']:\n",
    "                    tables.append({\n",
    "                        'caption': table_chunk.get('caption_tex', ''),\n",
    "                        'csv_uri': table_chunk.get('csv_uri', ''),\n",
    "                        'headers': table_chunk.get('headers', []),\n",
    "                        'text': table_chunk.get('text', '')\n",
    "                    })\n",
    "        return tables\n",
    "    \n",
    "    def get_manuscript_summary(self):\n",
    "        \"\"\"Get comprehensive manuscript summary\"\"\"\n",
    "        summary = {\n",
    "            'total_chunks': len(self.chunks),\n",
    "            'sections': len(self.sections),\n",
    "            'total_equations': len(self.equations),\n",
    "            'total_figures': len(self.figures),\n",
    "            'total_tables': len(self.tables),\n",
    "            'section_breakdown': {}\n",
    "        }\n",
    "        \n",
    "        for section_key, content in self.sections.items():\n",
    "            summary['section_breakdown'][section_key] = {\n",
    "                'prose_chunks': len(content['prose']),\n",
    "                'equations': len(content['equations']),\n",
    "                'figures': len(content['figures']),\n",
    "                'tables': len(content['tables'])\n",
    "            }\n",
    "        \n",
    "        return summary\n",
    "\n",
    "# Create manuscript analysis functions\n",
    "class ManuscriptReviewer:\n",
    "    def __init__(self, denario_instance):\n",
    "        self.den = denario_instance\n",
    "        self.manuscript_text = \"\"\n",
    "        self.sections = {}\n",
    "        self.issues = []\n",
    "        self.citations = []\n",
    "        \n",
    "    def load_manuscript(self, file_path):\n",
    "        \"\"\"Load manuscript from file\"\"\"\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                self.manuscript_text = f.read()\n",
    "            print(f\"‚úÖ Manuscript loaded: {file_path}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading manuscript: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def analyze_sections(self):\n",
    "        \"\"\"Analyze manuscript sections for completeness\"\"\"\n",
    "        # Common section patterns\n",
    "        section_patterns = {\n",
    "            'Abstract': r'\\\\abstract\\{(.*?)\\}',\n",
    "            'Introduction': r'\\\\section\\{Introduction\\}(.*?)(?=\\\\section|\\\\end)',\n",
    "            'Methods': r'\\\\section\\{Methodology?\\}(.*?)(?=\\\\section|\\\\end)',\n",
    "            'Results': r'\\\\section\\{Results?\\}(.*?)(?=\\\\section|\\\\end)',\n",
    "            'Discussion': r'\\\\section\\{Discussion\\}(.*?)(?=\\\\section|\\\\end)',\n",
    "            'Conclusion': r'\\\\section\\{Conclusion\\}(.*?)(?=\\\\section|\\\\end)'\n",
    "        }\n",
    "        \n",
    "        self.sections = {}\n",
    "        for section_name, pattern in section_patterns.items():\n",
    "            matches = re.findall(pattern, self.manuscript_text, re.DOTALL | re.IGNORECASE)\n",
    "            if matches:\n",
    "                self.sections[section_name] = matches[0].strip()\n",
    "            else:\n",
    "                self.sections[section_name] = \"\"\n",
    "                self.issues.append(f\"Missing or incomplete {section_name} section\")\n",
    "        \n",
    "        return self.sections\n",
    "    \n",
    "    def check_citations(self):\n",
    "        \"\"\"Check for citation completeness\"\"\"\n",
    "        # Find citation patterns\n",
    "        citation_patterns = [\n",
    "            r'\\\\cite\\{[^}]+\\}',  # LaTeX citations\n",
    "            r'\\[[0-9]+\\]',       # Numbered citations\n",
    "            r'\\([A-Za-z]+ et al\\., [0-9]{4}\\)'  # Author-year citations\n",
    "        ]\n",
    "        \n",
    "        found_citations = []\n",
    "        for pattern in citation_patterns:\n",
    "            found_citations.extend(re.findall(pattern, self.manuscript_text))\n",
    "        \n",
    "        # Check for uncited claims (simple heuristic)\n",
    "        sentences = re.split(r'[.!?]+', self.manuscript_text)\n",
    "        uncited_sentences = []\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            if len(sentence.strip()) > 50:  # Substantial sentence\n",
    "                has_citation = any(pattern in sentence for pattern in citation_patterns)\n",
    "                if not has_citation and any(word in sentence.lower() for word in \n",
    "                    ['show', 'demonstrate', 'prove', 'indicate', 'suggest', 'reveal']):\n",
    "                    uncited_sentences.append(sentence.strip())\n",
    "        \n",
    "        self.citations = found_citations\n",
    "        if uncited_sentences:\n",
    "            self.issues.append(f\"Found {len(uncited_sentences)} potentially uncited claims\")\n",
    "        \n",
    "        return {\n",
    "            'total_citations': len(found_citations),\n",
    "            'uncited_claims': len(uncited_sentences),\n",
    "            'uncited_sentences': uncited_sentences[:5]  # Show first 5\n",
    "        }\n",
    "    \n",
    "    def check_mathematics(self):\n",
    "        \"\"\"Check mathematical content for completeness\"\"\"\n",
    "        math_patterns = {\n",
    "            'equations': r'\\\\begin\\{equation\\}(.*?)\\\\end\\{equation\\}',\n",
    "            'inline_math': r'\\$([^$]+)\\$',\n",
    "            'display_math': r'\\$\\$([^$]+)\\$\\$',\n",
    "            'proofs': r'\\\\begin\\{proof\\}(.*?)\\\\end\\{proof\\}',\n",
    "            'theorems': r'\\\\begin\\{theorem\\}(.*?)\\\\end\\{theorem\\}'\n",
    "        }\n",
    "        \n",
    "        math_content = {}\n",
    "        for math_type, pattern in math_patterns.items():\n",
    "            matches = re.findall(pattern, self.manuscript_text, re.DOTALL)\n",
    "            math_content[math_type] = matches\n",
    "        \n",
    "        # Check for incomplete derivations\n",
    "        incomplete_derivations = []\n",
    "        for eq in math_content['equations']:\n",
    "            if '...' in eq or '\\\\ldots' in eq:\n",
    "                incomplete_derivations.append(eq[:100] + \"...\")\n",
    "        \n",
    "        if incomplete_derivations:\n",
    "            self.issues.append(f\"Found {len(incomplete_derivations)} potentially incomplete derivations\")\n",
    "        \n",
    "        return {\n",
    "            'equations': len(math_content['equations']),\n",
    "            'inline_math': len(math_content['inline_math']),\n",
    "            'proofs': len(math_content['proofs']),\n",
    "            'theorems': len(math_content['theorems']),\n",
    "            'incomplete_derivations': incomplete_derivations\n",
    "        }\n",
    "    \n",
    "    def generate_report(self):\n",
    "        \"\"\"Generate comprehensive analysis report\"\"\"\n",
    "        sections = self.analyze_sections()\n",
    "        citations = self.check_citations()\n",
    "        math = self.check_mathematics()\n",
    "        \n",
    "        report = {\n",
    "            'sections': sections,\n",
    "            'citations': citations,\n",
    "            'mathematics': math,\n",
    "            'issues': self.issues,\n",
    "            'total_issues': len(self.issues)\n",
    "        }\n",
    "        \n",
    "        return report\n",
    "\n",
    "# Initialize the reviewer\n",
    "den = Denario(project_dir=\"manuscript_review\")\n",
    "reviewer = ManuscriptReviewer(den)\n",
    "\n",
    "print(\"üîç Manuscript Reviewer initialized\")\n",
    "print(\"Ready to analyze your manuscript!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß JSONL analysis functions loaded!\n"
     ]
    }
   ],
   "source": [
    "# JSONL analysis functions\n",
    "def generate_jsonl_analysis_report(jsonl_parser):\n",
    "    \"\"\"Generate analysis report for JSONL manuscript\"\"\"\n",
    "    summary = jsonl_parser.get_manuscript_summary()\n",
    "    \n",
    "    # Analyze section completeness\n",
    "    sections = {}\n",
    "    section_names = ['Abstract', 'Introduction', 'Methods', 'Results', 'Discussion', 'Conclusion']\n",
    "    \n",
    "    for section_name in section_names:\n",
    "        section_text = jsonl_parser.get_section_text(section_name)\n",
    "        sections[section_name] = section_text\n",
    "        \n",
    "    # Count citations (simple heuristic)\n",
    "    total_citations = 0\n",
    "    for chunk in jsonl_parser.chunks:\n",
    "        if chunk.get('type') == 'prose':\n",
    "            text = chunk.get('text', '')\n",
    "            # Count various citation patterns\n",
    "            citations = len(re.findall(r'\\\\cite\\{[^}]+\\}', text))\n",
    "            citations += len(re.findall(r'\\[[0-9]+\\]', text))\n",
    "            citations += len(re.findall(r'\\([A-Za-z]+ et al\\., [0-9]{4}\\)', text))\n",
    "            total_citations += citations\n",
    "    \n",
    "    # Analyze mathematics\n",
    "    math_content = {\n",
    "        'equations': len(jsonl_parser.equations),\n",
    "        'inline_math': 0,  # Would need to count inline math in prose chunks\n",
    "        'proofs': 0,\n",
    "        'theorems': 0,\n",
    "        'incomplete_derivations': []\n",
    "    }\n",
    "    \n",
    "    # Check for incomplete derivations\n",
    "    for eq in jsonl_parser.equations:\n",
    "        eq_tex = eq.get('equation_tex', '')\n",
    "        if '...' in eq_tex or '\\\\ldots' in eq_tex:\n",
    "            math_content['incomplete_derivations'].append(eq_tex[:100] + \"...\")\n",
    "    \n",
    "    # Identify issues\n",
    "    issues = []\n",
    "    for section_name in section_names:\n",
    "        if not sections[section_name].strip():\n",
    "            issues.append(f\"Missing or incomplete {section_name} section\")\n",
    "    \n",
    "    if math_content['incomplete_derivations']:\n",
    "        issues.append(f\"Found {len(math_content['incomplete_derivations'])} potentially incomplete derivations\")\n",
    "    \n",
    "    return {\n",
    "        'sections': sections,\n",
    "        'citations': {\n",
    "            'total_citations': total_citations,\n",
    "            'uncited_claims': 0,  # Would need more sophisticated analysis\n",
    "            'uncited_sentences': []\n",
    "        },\n",
    "        'mathematics': math_content,\n",
    "        'issues': issues,\n",
    "        'total_issues': len(issues),\n",
    "        'jsonl_summary': summary\n",
    "    }\n",
    "\n",
    "def display_jsonl_analysis_results(report):\n",
    "    \"\"\"Display analysis results for JSONL manuscript\"\"\"\n",
    "    print(\"üìä JSONL MANUSCRIPT ANALYSIS REPORT\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # JSONL summary\n",
    "    if 'jsonl_summary' in report:\n",
    "        summary = report['jsonl_summary']\n",
    "        print(f\"\\nüìÑ DOCUMENT STRUCTURE:\")\n",
    "        print(f\"  Total chunks: {summary['total_chunks']}\")\n",
    "        print(f\"  Sections: {summary['sections']}\")\n",
    "        print(f\"  Equations: {summary['total_equations']}\")\n",
    "        print(f\"  Figures: {summary['total_figures']}\")\n",
    "        print(f\"  Tables: {summary['total_tables']}\")\n",
    "    \n",
    "    # Section completeness\n",
    "    print(\"\\nüìù SECTION COMPLETENESS:\")\n",
    "    for section, content in report['sections'].items():\n",
    "        status = \"‚úÖ\" if content.strip() else \"‚ùå\"\n",
    "        length = len(content.split()) if content else 0\n",
    "        print(f\"  {status} {section}: {length} words\")\n",
    "    \n",
    "    # Citation analysis\n",
    "    print(f\"\\nüìö CITATION ANALYSIS:\")\n",
    "    print(f\"  Total citations found: {report['citations']['total_citations']}\")\n",
    "    \n",
    "    # Mathematical content\n",
    "    print(f\"\\nüßÆ MATHEMATICAL CONTENT:\")\n",
    "    print(f\"  Equations: {report['mathematics']['equations']}\")\n",
    "    print(f\"  Inline math: {report['mathematics']['inline_math']}\")\n",
    "    print(f\"  Proofs: {report['mathematics']['proofs']}\")\n",
    "    print(f\"  Theorems: {report['mathematics']['theorems']}\")\n",
    "    \n",
    "    if report['mathematics']['incomplete_derivations']:\n",
    "        print(f\"  ‚ö†Ô∏è  Incomplete derivations: {len(report['mathematics']['incomplete_derivations'])}\")\n",
    "    \n",
    "    # Issues summary\n",
    "    print(f\"\\n‚ö†Ô∏è  ISSUES FOUND: {report['total_issues']}\")\n",
    "    for i, issue in enumerate(report['issues'], 1):\n",
    "        print(f\"  {i}. {issue}\")\n",
    "\n",
    "print(\"üîß JSONL analysis functions loaded!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Interactive Manuscript Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Upload your manuscript to begin analysis:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b42e53c9fc144df6b10e5d18ae45db72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='.tex,.txt,.md,.docx', description='Upload Manuscript')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Interactive manuscript upload and analysis\n",
    "def create_upload_widget():\n",
    "    \"\"\"Create file upload widget for manuscript\"\"\"\n",
    "    upload_widget = widgets.FileUpload(\n",
    "        accept='.tex,.txt,.md,.docx',\n",
    "        multiple=False,\n",
    "        description='Upload Manuscript',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    return upload_widget\n",
    "\n",
    "def analyze_manuscript_uploaded(change):\n",
    "    \"\"\"Analyze uploaded manuscript\"\"\"\n",
    "    if change['new']:\n",
    "        # Get the uploaded file\n",
    "        uploaded_file = list(change['owner'].value.values())[0]\n",
    "        \n",
    "        # Save to temporary file\n",
    "        temp_path = f\"/tmp/manuscript_{uploaded_file['name']}\"\n",
    "        with open(temp_path, 'wb') as f:\n",
    "            f.write(uploaded_file['content'])\n",
    "        \n",
    "        # Load and analyze\n",
    "        if reviewer.load_manuscript(temp_path):\n",
    "            report = reviewer.generate_report()\n",
    "            display_analysis_results(report)\n",
    "        else:\n",
    "            print(\"‚ùå Failed to load manuscript\")\n",
    "\n",
    "def display_analysis_results(report):\n",
    "    \"\"\"Display comprehensive analysis results\"\"\"\n",
    "    print(\"üìä MANUSCRIPT ANALYSIS REPORT\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Section completeness\n",
    "    print(\"\\nüìù SECTION COMPLETENESS:\")\n",
    "    for section, content in report['sections'].items():\n",
    "        status = \"‚úÖ\" if content.strip() else \"‚ùå\"\n",
    "        length = len(content.split()) if content else 0\n",
    "        print(f\"  {status} {section}: {length} words\")\n",
    "    \n",
    "    # Citation analysis\n",
    "    print(f\"\\nüìö CITATION ANALYSIS:\")\n",
    "    print(f\"  Total citations found: {report['citations']['total_citations']}\")\n",
    "    print(f\"  Potentially uncited claims: {report['citations']['uncited_claims']}\")\n",
    "    \n",
    "    if report['citations']['uncited_sentences']:\n",
    "        print(\"  Examples of uncited claims:\")\n",
    "        for i, sentence in enumerate(report['citations']['uncited_sentences'], 1):\n",
    "            print(f\"    {i}. {sentence[:100]}...\")\n",
    "    \n",
    "    # Mathematical content\n",
    "    print(f\"\\nüßÆ MATHEMATICAL CONTENT:\")\n",
    "    print(f\"  Equations: {report['mathematics']['equations']}\")\n",
    "    print(f\"  Inline math: {report['mathematics']['inline_math']}\")\n",
    "    print(f\"  Proofs: {report['mathematics']['proofs']}\")\n",
    "    print(f\"  Theorems: {report['mathematics']['theorems']}\")\n",
    "    \n",
    "    if report['mathematics']['incomplete_derivations']:\n",
    "        print(f\"  ‚ö†Ô∏è  Incomplete derivations: {len(report['mathematics']['incomplete_derivations'])}\")\n",
    "    \n",
    "    # Issues summary\n",
    "    print(f\"\\n‚ö†Ô∏è  ISSUES FOUND: {report['total_issues']}\")\n",
    "    for i, issue in enumerate(report['issues'], 1):\n",
    "        print(f\"  {i}. {issue}\")\n",
    "\n",
    "# Create upload widget\n",
    "upload_widget = create_upload_widget()\n",
    "upload_widget.observe(analyze_manuscript_uploaded, names='value')\n",
    "\n",
    "print(\"üìÅ Upload your manuscript to begin analysis:\")\n",
    "display(upload_widget)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Content Generation and Enhancement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced ManuscriptReviewer with content generation capabilities\n",
    "class EnhancedManuscriptReviewer(ManuscriptReviewer):\n",
    "    def __init__(self, denario_instance):\n",
    "        super().__init__(denario_instance)\n",
    "        self.generated_content = {}\n",
    "        self.citation_database = []\n",
    "        \n",
    "    def generate_missing_content(self, section_name, context=\"\"):\n",
    "        \"\"\"Generate content for incomplete sections using Denario\"\"\"\n",
    "        try:\n",
    "            # Set up the research context\n",
    "            self.den.set_data_description(f\"Generate content for {section_name} section. Context: {context}\")\n",
    "            \n",
    "            # Use Denario to generate ideas and methodology\n",
    "            idea = self.den.get_idea_fast()\n",
    "            method = self.den.get_method_fast()\n",
    "            \n",
    "            # Generate results if needed\n",
    "            if section_name.lower() in ['results', 'discussion']:\n",
    "                results = self.den.get_results()\n",
    "                self.generated_content[section_name] = {\n",
    "                    'idea': idea,\n",
    "                    'method': method,\n",
    "                    'results': results\n",
    "                }\n",
    "            else:\n",
    "                self.generated_content[section_name] = {\n",
    "                    'idea': idea,\n",
    "                    'method': method\n",
    "                }\n",
    "            \n",
    "            print(f\"‚úÖ Generated content for {section_name}\")\n",
    "            return self.generated_content[section_name]\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error generating content for {section_name}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def add_citations_to_content(self, content, topic):\n",
    "        \"\"\"Add relevant citations to generated content\"\"\"\n",
    "        try:\n",
    "            # Use Denario's research capabilities to find relevant papers\n",
    "            self.den.set_data_description(f\"Find relevant citations for: {topic}\")\n",
    "            \n",
    "            # Generate research ideas that would include citations\n",
    "            research_ideas = self.den.get_idea_fast()\n",
    "            \n",
    "            # Extract potential citation topics\n",
    "            citation_topics = self._extract_citation_topics(research_ideas)\n",
    "            \n",
    "            # Generate cited content\n",
    "            cited_content = self._integrate_citations(content, citation_topics)\n",
    "            \n",
    "            return cited_content\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error adding citations: {e}\")\n",
    "            return content\n",
    "    \n",
    "    def _extract_citation_topics(self, research_text):\n",
    "        \"\"\"Extract topics that need citations\"\"\"\n",
    "        # Simple keyword extraction for citation topics\n",
    "        keywords = ['method', 'approach', 'technique', 'model', 'algorithm', \n",
    "                   'framework', 'theory', 'concept', 'finding', 'result']\n",
    "        \n",
    "        topics = []\n",
    "        for keyword in keywords:\n",
    "            if keyword in research_text.lower():\n",
    "                topics.append(keyword)\n",
    "        \n",
    "        return topics\n",
    "    \n",
    "    def _integrate_citations(self, content, topics):\n",
    "        \"\"\"Integrate citations into content\"\"\"\n",
    "        cited_content = content\n",
    "        for i, topic in enumerate(topics[:3]):  # Limit to 3 citations\n",
    "            citation = f\"[{topic.capitalize()} et al., 2024]\"\n",
    "            cited_content = cited_content.replace(topic, f\"{topic} {citation}\")\n",
    "        \n",
    "        return cited_content\n",
    "    \n",
    "    def verify_mathematics(self, equation_text):\n",
    "        \"\"\"Verify mathematical derivations using Denario\"\"\"\n",
    "        try:\n",
    "            # Set up mathematical verification context\n",
    "            self.den.set_data_description(f\"Verify this mathematical derivation: {equation_text}\")\n",
    "            \n",
    "            # Use Denario to analyze the mathematics\n",
    "            analysis = self.den.get_idea_fast()\n",
    "            \n",
    "            # Check for common mathematical errors\n",
    "            verification_result = self._check_math_errors(equation_text, analysis)\n",
    "            \n",
    "            return verification_result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error verifying mathematics: {e}\")\n",
    "            return {\"status\": \"error\", \"message\": str(e)}\n",
    "    \n",
    "    def _check_math_errors(self, equation, analysis):\n",
    "        \"\"\"Check for mathematical errors\"\"\"\n",
    "        errors = []\n",
    "        \n",
    "        # Check for common LaTeX errors\n",
    "        if '\\\\' in equation and not equation.count('{') == equation.count('}'):\n",
    "            errors.append(\"Mismatched braces in LaTeX\")\n",
    "        \n",
    "        # Check for division by zero\n",
    "        if '/0' in equation or '/ 0' in equation:\n",
    "            errors.append(\"Potential division by zero\")\n",
    "        \n",
    "        # Check for undefined variables\n",
    "        if 'undefined' in analysis.lower():\n",
    "            errors.append(\"Undefined variables detected\")\n",
    "        \n",
    "        return {\n",
    "            \"status\": \"verified\" if not errors else \"errors_found\",\n",
    "            \"errors\": errors,\n",
    "            \"analysis\": analysis\n",
    "        }\n",
    "    \n",
    "    def generate_complete_manuscript(self):\n",
    "        \"\"\"Generate a complete manuscript with all sections\"\"\"\n",
    "        complete_manuscript = {}\n",
    "        \n",
    "        # Generate each section\n",
    "        sections = ['Abstract', 'Introduction', 'Methods', 'Results', 'Discussion', 'Conclusion']\n",
    "        \n",
    "        for section in sections:\n",
    "            if not self.sections.get(section, \"\").strip():\n",
    "                print(f\"üîÑ Generating {section} section...\")\n",
    "                content = self.generate_missing_content(section)\n",
    "                if content:\n",
    "                    # Add citations\n",
    "                    cited_content = self.add_citations_to_content(\n",
    "                        content.get('idea', ''), \n",
    "                        section\n",
    "                    )\n",
    "                    complete_manuscript[section] = cited_content\n",
    "                else:\n",
    "                    complete_manuscript[section] = f\"[{section} content generation failed]\"\n",
    "            else:\n",
    "                complete_manuscript[section] = self.sections[section]\n",
    "        \n",
    "        return complete_manuscript\n",
    "\n",
    "# Referee-aware manuscript reviewer with comment parsing and response generation\n",
    "class RefereeAwareManuscriptReviewer(EnhancedManuscriptReviewer):\n",
    "    def __init__(self, denario_instance):\n",
    "        super().__init__(denario_instance)\n",
    "        self.referee_comments = {}\n",
    "        self.priority_issues = []\n",
    "        self.comment_sections = {}\n",
    "        \n",
    "    def load_referee_report(self, report_text):\n",
    "        \"\"\"Load and parse referee report from various formats\"\"\"\n",
    "        try:\n",
    "            # Try JSON format first\n",
    "            if report_text.strip().startswith('{'):\n",
    "                self.referee_comments = json.loads(report_text)\n",
    "                print(\"‚úÖ Loaded JSON format referee report\")\n",
    "            else:\n",
    "                # Parse text format\n",
    "                self.referee_comments = self._parse_text_comments(report_text)\n",
    "                print(\"‚úÖ Loaded text format referee report\")\n",
    "            \n",
    "            # Identify priority issues\n",
    "            self.priority_issues = self._identify_priority_issues()\n",
    "            self.comment_sections = self._organize_comments_by_section()\n",
    "            \n",
    "            print(f\"üìã Parsed {len(self.priority_issues)} priority issues\")\n",
    "            print(f\"üìù Organized comments for {len(self.comment_sections)} sections\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading referee report: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def _parse_text_comments(self, text):\n",
    "        \"\"\"Parse text-based referee comments into structured format\"\"\"\n",
    "        comments = {\n",
    "            'major_issues': [],\n",
    "            'minor_issues': [],\n",
    "            'suggestions': [],\n",
    "            'overall_recommendation': 'Unknown'\n",
    "        }\n",
    "        \n",
    "        # Extract overall recommendation\n",
    "        rec_pattern = r'(?:recommendation|decision)[:\\s]*(accept|reject|major revision|minor revision|revise and resubmit)'\n",
    "        rec_match = re.search(rec_pattern, text, re.IGNORECASE)\n",
    "        if rec_match:\n",
    "            comments['overall_recommendation'] = rec_match.group(1).title()\n",
    "        \n",
    "        # Parse major issues\n",
    "        major_pattern = r'major issues?[:\\s]*(.*?)(?=minor|suggestions|$|recommendation)'\n",
    "        major_match = re.search(major_pattern, text, re.IGNORECASE | re.DOTALL)\n",
    "        if major_match:\n",
    "            major_text = major_match.group(1).strip()\n",
    "            major_issues = self._extract_individual_comments(major_text)\n",
    "            comments['major_issues'] = major_issues\n",
    "        \n",
    "        # Parse minor issues\n",
    "        minor_pattern = r'minor issues?[:\\s]*(.*?)(?=major|suggestions|$|recommendation)'\n",
    "        minor_match = re.search(minor_pattern, text, re.IGNORECASE | re.DOTALL)\n",
    "        if minor_match:\n",
    "            minor_text = minor_match.group(1).strip()\n",
    "            minor_issues = self._extract_individual_comments(minor_text)\n",
    "            comments['minor_issues'] = minor_issues\n",
    "        \n",
    "        # Parse suggestions\n",
    "        suggestions_pattern = r'suggestions?[:\\s]*(.*?)(?=major|minor|$|recommendation)'\n",
    "        suggestions_match = re.search(suggestions_pattern, text, re.IGNORECASE | re.DOTALL)\n",
    "        if suggestions_match:\n",
    "            suggestions_text = suggestions_match.group(1).strip()\n",
    "            suggestions = self._extract_individual_comments(suggestions_text)\n",
    "            comments['suggestions'] = suggestions\n",
    "        \n",
    "        return comments\n",
    "    \n",
    "    def _extract_individual_comments(self, text):\n",
    "        \"\"\"Extract individual comments from a section\"\"\"\n",
    "        comments = []\n",
    "        \n",
    "        # Split by numbered items or bullet points\n",
    "        items = re.split(r'\\n\\s*(?:\\d+\\.|\\*|\\-)\\s*', text)\n",
    "        \n",
    "        for item in items:\n",
    "            item = item.strip()\n",
    "            if len(item) > 10:  # Filter out very short items\n",
    "                # Try to extract section and line references\n",
    "                section_match = re.search(r'(?:section|chapter)\\s*([a-zA-Z0-9\\s]+)', item, re.IGNORECASE)\n",
    "                line_match = re.search(r'line\\s*(\\d+)', item, re.IGNORECASE)\n",
    "                \n",
    "                comment = {\n",
    "                    'text': item,\n",
    "                    'section': section_match.group(1).strip() if section_match else 'General',\n",
    "                    'line': int(line_match.group(1)) if line_match else None\n",
    "                }\n",
    "                comments.append(comment)\n",
    "        \n",
    "        return comments\n",
    "    \n",
    "    def _identify_priority_issues(self):\n",
    "        \"\"\"Identify and prioritize issues from referee comments\"\"\"\n",
    "        priority_issues = []\n",
    "        \n",
    "        # Major issues are highest priority\n",
    "        for issue in self.referee_comments.get('major_issues', []):\n",
    "            priority_issues.append({\n",
    "                'priority': 'HIGH',\n",
    "                'type': 'Major Issue',\n",
    "                'section': issue.get('section', 'General'),\n",
    "                'text': issue.get('text', ''),\n",
    "                'line': issue.get('line')\n",
    "            })\n",
    "        \n",
    "        # Minor issues are medium priority\n",
    "        for issue in self.referee_comments.get('minor_issues', []):\n",
    "            priority_issues.append({\n",
    "                'priority': 'MEDIUM',\n",
    "                'type': 'Minor Issue',\n",
    "                'section': issue.get('section', 'General'),\n",
    "                'text': issue.get('text', ''),\n",
    "                'line': issue.get('line')\n",
    "            })\n",
    "        \n",
    "        # Suggestions are lower priority\n",
    "        for suggestion in self.referee_comments.get('suggestions', []):\n",
    "            priority_issues.append({\n",
    "                'priority': 'LOW',\n",
    "                'type': 'Suggestion',\n",
    "                'section': suggestion.get('section', 'General'),\n",
    "                'text': suggestion.get('text', ''),\n",
    "                'line': suggestion.get('line')\n",
    "            })\n",
    "        \n",
    "        return priority_issues\n",
    "    \n",
    "    def _organize_comments_by_section(self):\n",
    "        \"\"\"Organize comments by manuscript section\"\"\"\n",
    "        section_comments = {}\n",
    "        \n",
    "        for issue in self.priority_issues:\n",
    "            section = issue['section']\n",
    "            if section not in section_comments:\n",
    "                section_comments[section] = []\n",
    "            section_comments[section].append(issue)\n",
    "        \n",
    "        return section_comments\n",
    "    \n",
    "    def generate_referee_response(self, section_name):\n",
    "        \"\"\"Generate content that addresses referee comments for a specific section\"\"\"\n",
    "        relevant_comments = self.comment_sections.get(section_name, [])\n",
    "        \n",
    "        if not relevant_comments:\n",
    "            print(f\"‚ÑπÔ∏è  No referee comments found for {section_name}\")\n",
    "            return None\n",
    "        \n",
    "        # Create context from referee comments\n",
    "        comment_context = f\"Address these referee comments for {section_name}:\\n\"\n",
    "        for i, comment in enumerate(relevant_comments, 1):\n",
    "            comment_context += f\"{i}. [{comment['priority']}] {comment['text']}\\n\"\n",
    "        \n",
    "        print(f\"üîÑ Generating response for {section_name} addressing {len(relevant_comments)} comments...\")\n",
    "        \n",
    "        # Generate content using Denario\n",
    "        response_content = self.generate_missing_content(section_name, comment_context)\n",
    "        \n",
    "        if response_content:\n",
    "            # Add specific responses to each comment\n",
    "            detailed_response = self._generate_detailed_responses(response_content, relevant_comments)\n",
    "            return detailed_response\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def _generate_detailed_responses(self, content, comments):\n",
    "        \"\"\"Generate detailed responses to specific referee comments\"\"\"\n",
    "        detailed_responses = {\n",
    "            'generated_content': content,\n",
    "            'comment_responses': []\n",
    "        }\n",
    "        \n",
    "        for comment in comments:\n",
    "            response = {\n",
    "                'comment': comment['text'],\n",
    "                'priority': comment['priority'],\n",
    "                'response': f\"Addressed in generated content: {comment['text'][:100]}...\"\n",
    "            }\n",
    "            detailed_responses['comment_responses'].append(response)\n",
    "        \n",
    "        return detailed_responses\n",
    "    \n",
    "    def generate_comprehensive_response(self):\n",
    "        \"\"\"Generate comprehensive response addressing all referee comments\"\"\"\n",
    "        comprehensive_response = {}\n",
    "        \n",
    "        # Get all sections with comments\n",
    "        sections_with_comments = list(self.comment_sections.keys())\n",
    "        \n",
    "        print(f\"üìù Generating comprehensive response for {len(sections_with_comments)} sections...\")\n",
    "        \n",
    "        for section in sections_with_comments:\n",
    "            print(f\"  üîÑ Processing {section}...\")\n",
    "            response = self.generate_referee_response(section)\n",
    "            if response:\n",
    "                comprehensive_response[section] = response\n",
    "        \n",
    "        return comprehensive_response\n",
    "    \n",
    "    def display_referee_summary(self):\n",
    "        \"\"\"Display summary of referee comments and responses\"\"\"\n",
    "        print(\"üìã REFEREE REPORT SUMMARY\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Overall recommendation\n",
    "        recommendation = self.referee_comments.get('overall_recommendation', 'Unknown')\n",
    "        print(f\"üìä Overall Recommendation: {recommendation}\")\n",
    "        \n",
    "        # Priority breakdown\n",
    "        high_priority = [i for i in self.priority_issues if i['priority'] == 'HIGH']\n",
    "        medium_priority = [i for i in self.priority_issues if i['priority'] == 'MEDIUM']\n",
    "        low_priority = [i for i in self.priority_issues if i['priority'] == 'LOW']\n",
    "        \n",
    "        print(f\"\\n‚ö†Ô∏è  Priority Issues:\")\n",
    "        print(f\"  üî¥ High Priority: {len(high_priority)}\")\n",
    "        print(f\"  üü° Medium Priority: {len(medium_priority)}\")\n",
    "        print(f\"  üü¢ Low Priority: {len(low_priority)}\")\n",
    "        \n",
    "        # Section breakdown\n",
    "        print(f\"\\nüìù Comments by Section:\")\n",
    "        for section, comments in self.comment_sections.items():\n",
    "            print(f\"  ‚Ä¢ {section}: {len(comments)} comments\")\n",
    "        \n",
    "        # Show high priority issues\n",
    "        if high_priority:\n",
    "            print(f\"\\nüî¥ HIGH PRIORITY ISSUES:\")\n",
    "            for i, issue in enumerate(high_priority[:3], 1):\n",
    "                print(f\"  {i}. [{issue['section']}] {issue['text'][:100]}...\")\n",
    "\n",
    "# Initialize enhanced reviewer\n",
    "enhanced_reviewer = EnhancedManuscriptReviewer(den)\n",
    "\n",
    "# Initialize referee-aware reviewer\n",
    "referee_reviewer = RefereeAwareManuscriptReviewer(den)\n",
    "\n",
    "print(\"üöÄ Enhanced Manuscript Reviewer with content generation capabilities initialized!\")\n",
    "print(\"üìã Referee-Aware Manuscript Reviewer with comment parsing initialized!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Referee Report Upload and Analysis Interface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Referee report upload and analysis interface\n",
    "def create_referee_report_interface():\n",
    "    \"\"\"Create interactive interface for referee report upload and analysis\"\"\"\n",
    "    \n",
    "    # Referee report upload widget\n",
    "    referee_upload = widgets.FileUpload(\n",
    "        accept='.txt,.md,.json',\n",
    "        multiple=False,\n",
    "        description='Upload Referee Report',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Text input for pasting referee comments\n",
    "    referee_text_input = widgets.Textarea(\n",
    "        value='',\n",
    "        placeholder='Or paste referee comments directly here...',\n",
    "        description='Referee Comments:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='100%', height='200px')\n",
    "    )\n",
    "    \n",
    "    # Load referee report button\n",
    "    load_referee_button = widgets.Button(\n",
    "        description='Load Referee Report',\n",
    "        button_style='info',\n",
    "        icon='upload'\n",
    "    )\n",
    "    \n",
    "    # Display referee summary button\n",
    "    summary_button = widgets.Button(\n",
    "        description='Show Referee Summary',\n",
    "        button_style='warning',\n",
    "        icon='list'\n",
    "    )\n",
    "    \n",
    "    # Generate responses button\n",
    "    generate_responses_button = widgets.Button(\n",
    "        description='Generate Responses',\n",
    "        button_style='success',\n",
    "        icon='reply'\n",
    "    )\n",
    "    \n",
    "    # Output area\n",
    "    referee_output = widgets.Output()\n",
    "    \n",
    "    def on_load_referee_clicked(b):\n",
    "        with referee_output:\n",
    "            referee_output.clear_output()\n",
    "            \n",
    "            # Check if file was uploaded\n",
    "            if referee_upload.value:\n",
    "                uploaded_file = list(referee_upload.value.values())[0]\n",
    "                report_text = uploaded_file['content'].decode('utf-8')\n",
    "                print(f\"üìÑ Loaded referee report from file: {uploaded_file['name']}\")\n",
    "            elif referee_text_input.value.strip():\n",
    "                report_text = referee_text_input.value\n",
    "                print(\"üìÑ Loaded referee report from text input\")\n",
    "            else:\n",
    "                print(\"‚ùå Please upload a file or paste referee comments\")\n",
    "                return\n",
    "            \n",
    "            # Load the referee report\n",
    "            if referee_reviewer.load_referee_report(report_text):\n",
    "                print(\"‚úÖ Referee report loaded successfully!\")\n",
    "                print(\"üìã Use 'Show Referee Summary' to see parsed comments\")\n",
    "                print(\"üîÑ Use 'Generate Responses' to create responses to comments\")\n",
    "            else:\n",
    "                print(\"‚ùå Failed to load referee report\")\n",
    "    \n",
    "    def on_show_summary_clicked(b):\n",
    "        with referee_output:\n",
    "            referee_output.clear_output()\n",
    "            \n",
    "            if not referee_reviewer.priority_issues:\n",
    "                print(\"‚ùå No referee report loaded. Please load a report first.\")\n",
    "                return\n",
    "            \n",
    "            referee_reviewer.display_referee_summary()\n",
    "    \n",
    "    def on_generate_responses_clicked(b):\n",
    "        with referee_output:\n",
    "            referee_output.clear_output()\n",
    "            \n",
    "            if not referee_reviewer.priority_issues:\n",
    "                print(\"‚ùå No referee report loaded. Please load a report first.\")\n",
    "                return\n",
    "            \n",
    "            print(\"üöÄ Generating comprehensive responses to referee comments...\")\n",
    "            print(\"=\" * 60)\n",
    "            \n",
    "            # Generate comprehensive response\n",
    "            comprehensive_response = referee_reviewer.generate_comprehensive_response()\n",
    "            \n",
    "            if comprehensive_response:\n",
    "                print(\"‚úÖ Generated responses for all sections with comments!\")\n",
    "                print(\"\\nüìù RESPONSE SUMMARY:\")\n",
    "                print(\"=\" * 30)\n",
    "                \n",
    "                for section, response in comprehensive_response.items():\n",
    "                    print(f\"\\nüîπ {section.upper()}:\")\n",
    "                    print(f\"  Generated content: {len(response['generated_content'].get('idea', ''))} characters\")\n",
    "                    print(f\"  Comments addressed: {len(response['comment_responses'])}\")\n",
    "                    \n",
    "                    # Show first few comment responses\n",
    "                    for i, comment_resp in enumerate(response['comment_responses'][:2], 1):\n",
    "                        print(f\"    {i}. [{comment_resp['priority']}] {comment_resp['comment'][:80]}...\")\n",
    "                \n",
    "                print(f\"\\nüíæ Responses generated for {len(comprehensive_response)} sections\")\n",
    "                print(\"üìÑ Use the content generation interface to refine individual sections\")\n",
    "            else:\n",
    "                print(\"‚ùå Failed to generate responses\")\n",
    "    \n",
    "    # Connect button events\n",
    "    load_referee_button.on_click(on_load_referee_clicked)\n",
    "    summary_button.on_click(on_show_summary_clicked)\n",
    "    generate_responses_button.on_click(on_generate_responses_clicked)\n",
    "    \n",
    "    # Layout\n",
    "    interface = widgets.VBox([\n",
    "        widgets.HTML(\"<h3>üìã Referee Report Analysis</h3>\"),\n",
    "        widgets.HTML(\"<p>Upload a referee report file or paste comments directly:</p>\"),\n",
    "        widgets.HBox([referee_upload, load_referee_button]),\n",
    "        referee_text_input,\n",
    "        widgets.HBox([summary_button, generate_responses_button]),\n",
    "        referee_output\n",
    "    ])\n",
    "    \n",
    "    return interface\n",
    "\n",
    "# Create and display referee report interface\n",
    "referee_interface = create_referee_report_interface()\n",
    "display(referee_interface)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5. Interactive Content Generation Interface\n",
    "\n",
    "# Interactive widgets for content generation\n",
    "def create_content_generation_interface():\n",
    "    \"\"\"Create interactive interface for content generation\"\"\"\n",
    "    \n",
    "    # Section selection\n",
    "    section_dropdown = widgets.Dropdown(\n",
    "        options=['Abstract', 'Introduction', 'Methods', 'Results', 'Discussion', 'Conclusion'],\n",
    "        value='Introduction',\n",
    "        description='Section:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Context input\n",
    "    context_text = widgets.Textarea(\n",
    "        value='',\n",
    "        placeholder='Enter context or topic for this section...',\n",
    "        description='Context:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='100%', height='100px')\n",
    "    )\n",
    "    \n",
    "    # Generate button\n",
    "    generate_button = widgets.Button(\n",
    "        description='Generate Content',\n",
    "        button_style='success',\n",
    "        icon='plus'\n",
    "    )\n",
    "    \n",
    "    # Output area\n",
    "    output_area = widgets.Output()\n",
    "    \n",
    "    def on_generate_clicked(b):\n",
    "        with output_area:\n",
    "            output_area.clear_output()\n",
    "            section = section_dropdown.value\n",
    "            context = context_text.value\n",
    "            \n",
    "            print(f\"üîÑ Generating content for {section}...\")\n",
    "            print(f\"Context: {context}\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            # Generate content\n",
    "            content = enhanced_reviewer.generate_missing_content(section, context)\n",
    "            \n",
    "            if content:\n",
    "                print(f\"‚úÖ Generated {section} content:\")\n",
    "                print(\"=\" * 30)\n",
    "                \n",
    "                for key, value in content.items():\n",
    "                    print(f\"\\n{key.upper()}:\")\n",
    "                    print(value)\n",
    "                    print(\"-\" * 20)\n",
    "                \n",
    "                # Add citations\n",
    "                print(\"\\nüìö Adding citations...\")\n",
    "                cited_content = enhanced_reviewer.add_citations_to_content(\n",
    "                    content.get('idea', ''), \n",
    "                    section\n",
    "                )\n",
    "                print(\"Cited content:\")\n",
    "                print(cited_content)\n",
    "            else:\n",
    "                print(\"‚ùå Failed to generate content\")\n",
    "    \n",
    "    generate_button.on_click(on_generate_clicked)\n",
    "    \n",
    "    # Layout\n",
    "    interface = widgets.VBox([\n",
    "        widgets.HTML(\"<h3>üìù Content Generation Interface</h3>\"),\n",
    "        widgets.HBox([section_dropdown, generate_button]),\n",
    "        context_text,\n",
    "        output_area\n",
    "    ])\n",
    "    \n",
    "    return interface\n",
    "\n",
    "# Create and display interface\n",
    "content_interface = create_content_generation_interface()\n",
    "display(content_interface)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-analysis function for ragbook converted files\n",
    "def auto_analyze_converted_jsonl():\n",
    "    \"\"\"Automatically analyze the most recently converted JSONL file\"\"\"\n",
    "    global current_jsonl_path\n",
    "    \n",
    "    if 'current_jsonl_path' in globals() and current_jsonl_path and os.path.exists(current_jsonl_path):\n",
    "        print(f\"üîÑ Auto-analyzing converted JSONL: {current_jsonl_path}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Load and analyze the JSONL file\n",
    "        jsonl_parser = JSONLManuscriptParser()\n",
    "        if jsonl_parser.load_jsonl(current_jsonl_path):\n",
    "            # Generate comprehensive analysis report\n",
    "            report = generate_jsonl_analysis_report(jsonl_parser)\n",
    "            display_jsonl_analysis_results(report)\n",
    "            \n",
    "            print(\"\\nüéØ RICH STRUCTURED ANALYSIS COMPLETE!\")\n",
    "            print(\"üìä This analysis includes:\")\n",
    "            print(\"  ‚Ä¢ Semantic prose chunks with context\")\n",
    "            print(\"  ‚Ä¢ Normalized mathematical equations\")\n",
    "            print(\"  ‚Ä¢ Figure metadata and captions\")\n",
    "            print(\"  ‚Ä¢ Table data exported to CSV\")\n",
    "            print(\"  ‚Ä¢ Cross-references and citations\")\n",
    "            \n",
    "            return True\n",
    "        else:\n",
    "            print(\"‚ùå Failed to load converted JSONL file\")\n",
    "            return False\n",
    "    else:\n",
    "        print(\"‚ÑπÔ∏è  No converted JSONL file found. Please convert a LaTeX file first.\")\n",
    "        return False\n",
    "\n",
    "# Create a button to trigger auto-analysis\n",
    "auto_analyze_button = widgets.Button(\n",
    "    description='Analyze Converted JSONL',\n",
    "    button_style='info',\n",
    "    icon='search'\n",
    ")\n",
    "\n",
    "def on_auto_analyze_clicked(b):\n",
    "    auto_analyze_converted_jsonl()\n",
    "\n",
    "auto_analyze_button.on_click(on_auto_analyze_clicked)\n",
    "\n",
    "print(\"üîÑ Auto-analysis function for ragbook conversions loaded!\")\n",
    "print(\"üí° Use the 'Analyze Converted JSONL' button below after converting a LaTeX file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the auto-analyze button\n",
    "display(auto_analyze_button)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced analysis function with JSONL support\n",
    "def analyze_manuscript_uploaded_enhanced(change):\n",
    "    \"\"\"Analyze uploaded manuscript with JSONL support\"\"\"\n",
    "    if change['new']:\n",
    "        # Get the uploaded file\n",
    "        uploaded_file = list(change['owner'].value.values())[0]\n",
    "        file_name = uploaded_file['name']\n",
    "        \n",
    "        # Save to temporary file\n",
    "        temp_path = f\"/tmp/manuscript_{file_name}\"\n",
    "        with open(temp_path, 'wb') as f:\n",
    "            f.write(uploaded_file['content'])\n",
    "        \n",
    "        # Check file type and use appropriate parser\n",
    "        if file_name.endswith('.jsonl'):\n",
    "            print(f\"üìÑ Processing JSONL file: {file_name}\")\n",
    "            print(\"üîç Using ragbook JSONL parser for structured analysis...\")\n",
    "            jsonl_parser = JSONLManuscriptParser()\n",
    "            if jsonl_parser.load_jsonl(temp_path):\n",
    "                # Generate analysis report for JSONL\n",
    "                report = generate_jsonl_analysis_report(jsonl_parser)\n",
    "                display_jsonl_analysis_results(report)\n",
    "                print(\"\\n‚úÖ JSONL analysis complete! Rich structured data detected.\")\n",
    "            else:\n",
    "                print(\"‚ùå Failed to load JSONL file\")\n",
    "        else:\n",
    "            print(f\"üìÑ Processing {file_name} with standard parser...\")\n",
    "            # Use regular manuscript reviewer for other formats\n",
    "            if reviewer.load_manuscript(temp_path):\n",
    "                report = reviewer.generate_report()\n",
    "                display_analysis_results(report)\n",
    "            else:\n",
    "                print(\"‚ùå Failed to load manuscript\")\n",
    "\n",
    "print(\"üöÄ Enhanced analysis function with JSONL support loaded!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Mathematical Verification Interface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mathematical verification interface\n",
    "def create_math_verification_interface():\n",
    "    \"\"\"Create interface for mathematical verification\"\"\"\n",
    "    \n",
    "    # Equation input\n",
    "    equation_input = widgets.Textarea(\n",
    "        value='',\n",
    "        placeholder='Enter LaTeX equation or mathematical expression to verify...',\n",
    "        description='Equation:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='100%', height='120px')\n",
    "    )\n",
    "    \n",
    "    # Verify button\n",
    "    verify_button = widgets.Button(\n",
    "        description='Verify Mathematics',\n",
    "        button_style='info',\n",
    "        icon='check'\n",
    "    )\n",
    "    \n",
    "    # Output area\n",
    "    math_output = widgets.Output()\n",
    "    \n",
    "    def on_verify_clicked(b):\n",
    "        with math_output:\n",
    "            math_output.clear_output()\n",
    "            equation = equation_input.value.strip()\n",
    "            \n",
    "            if not equation:\n",
    "                print(\"‚ùå Please enter an equation to verify\")\n",
    "                return\n",
    "            \n",
    "            print(f\"üßÆ Verifying equation: {equation}\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            # Verify the mathematics\n",
    "            result = enhanced_reviewer.verify_mathematics(equation)\n",
    "            \n",
    "            if result['status'] == 'verified':\n",
    "                print(\"‚úÖ Mathematics verification passed!\")\n",
    "                print(f\"Analysis: {result['analysis']}\")\n",
    "            elif result['status'] == 'errors_found':\n",
    "                print(\"‚ö†Ô∏è  Mathematical errors detected:\")\n",
    "                for error in result['errors']:\n",
    "                    print(f\"  ‚Ä¢ {error}\")\n",
    "                print(f\"Analysis: {result['analysis']}\")\n",
    "            else:\n",
    "                print(f\"‚ùå Verification failed: {result['message']}\")\n",
    "    \n",
    "    verify_button.on_click(on_verify_clicked)\n",
    "    \n",
    "    # Layout\n",
    "    interface = widgets.VBox([\n",
    "        widgets.HTML(\"<h3>üßÆ Mathematical Verification</h3>\"),\n",
    "        equation_input,\n",
    "        verify_button,\n",
    "        math_output\n",
    "    ])\n",
    "    \n",
    "    return interface\n",
    "\n",
    "# Create and display interface\n",
    "math_interface = create_math_verification_interface()\n",
    "display(math_interface)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Complete Manuscript Generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete manuscript generation interface\n",
    "def create_complete_manuscript_interface():\n",
    "    \"\"\"Create interface for generating complete manuscripts\"\"\"\n",
    "    \n",
    "    # Generate complete manuscript button\n",
    "    generate_complete_button = widgets.Button(\n",
    "        description='Generate Complete Manuscript',\n",
    "        button_style='warning',\n",
    "        icon='file-text',\n",
    "        layout=widgets.Layout(width='300px', height='50px')\n",
    "    )\n",
    "    \n",
    "    # Export options\n",
    "    export_format = widgets.Dropdown(\n",
    "        options=['LaTeX', 'Markdown', 'Plain Text'],\n",
    "        value='LaTeX',\n",
    "        description='Export Format:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Output area\n",
    "    complete_output = widgets.Output()\n",
    "    \n",
    "    def on_generate_complete_clicked(b):\n",
    "        with complete_output:\n",
    "            complete_output.clear_output()\n",
    "            \n",
    "            print(\"üöÄ Generating complete manuscript...\")\n",
    "            print(\"=\" * 50)\n",
    "            \n",
    "            # Generate complete manuscript\n",
    "            complete_manuscript = enhanced_reviewer.generate_complete_manuscript()\n",
    "            \n",
    "            if complete_manuscript:\n",
    "                print(\"‚úÖ Complete manuscript generated!\")\n",
    "                print(\"\\nüìÑ MANUSCRIPT SECTIONS:\")\n",
    "                print(\"=\" * 30)\n",
    "                \n",
    "                for section, content in complete_manuscript.items():\n",
    "                    print(f\"\\n{section.upper()}:\")\n",
    "                    print(\"-\" * 20)\n",
    "                    print(content[:500] + \"...\" if len(content) > 500 else content)\n",
    "                    print(f\"[{len(content)} characters]\")\n",
    "                \n",
    "                # Export functionality\n",
    "                export_format_val = export_format.value\n",
    "                print(f\"\\nüíæ Exporting as {export_format_val}...\")\n",
    "                \n",
    "                if export_format_val == 'LaTeX':\n",
    "                    export_latex(complete_manuscript)\n",
    "                elif export_format_val == 'Markdown':\n",
    "                    export_markdown(complete_manuscript)\n",
    "                else:\n",
    "                    export_text(complete_manuscript)\n",
    "                \n",
    "            else:\n",
    "                print(\"‚ùå Failed to generate complete manuscript\")\n",
    "    \n",
    "    def export_latex(manuscript):\n",
    "        \"\"\"Export manuscript as LaTeX\"\"\"\n",
    "        latex_content = \"\\\\documentclass{article}\\n\\\\begin{document}\\n\\n\"\n",
    "        \n",
    "        for section, content in manuscript.items():\n",
    "            if section == 'Abstract':\n",
    "                latex_content += f\"\\\\abstract{{{content}}}\\n\\n\"\n",
    "            else:\n",
    "                latex_content += f\"\\\\section{{{section}}}\\n{content}\\n\\n\"\n",
    "        \n",
    "        latex_content += \"\\\\end{document}\"\n",
    "        \n",
    "        # Save to file\n",
    "        with open('/tmp/complete_manuscript.tex', 'w') as f:\n",
    "            f.write(latex_content)\n",
    "        \n",
    "        print(\"‚úÖ LaTeX manuscript saved to /tmp/complete_manuscript.tex\")\n",
    "    \n",
    "    def export_markdown(manuscript):\n",
    "        \"\"\"Export manuscript as Markdown\"\"\"\n",
    "        markdown_content = \"# Complete Manuscript\\n\\n\"\n",
    "        \n",
    "        for section, content in manuscript.items():\n",
    "            markdown_content += f\"## {section}\\n\\n{content}\\n\\n\"\n",
    "        \n",
    "        # Save to file\n",
    "        with open('/tmp/complete_manuscript.md', 'w') as f:\n",
    "            f.write(markdown_content)\n",
    "        \n",
    "        print(\"‚úÖ Markdown manuscript saved to /tmp/complete_manuscript.md\")\n",
    "    \n",
    "    def export_text(manuscript):\n",
    "        \"\"\"Export manuscript as plain text\"\"\"\n",
    "        text_content = \"COMPLETE MANUSCRIPT\\n\" + \"=\" * 50 + \"\\n\\n\"\n",
    "        \n",
    "        for section, content in manuscript.items():\n",
    "            text_content += f\"{section.upper()}\\n\" + \"-\" * 20 + \"\\n{content}\\n\\n\"\n",
    "        \n",
    "        # Save to file\n",
    "        with open('/tmp/complete_manuscript.txt', 'w') as f:\n",
    "            f.write(text_content)\n",
    "        \n",
    "        print(\"‚úÖ Text manuscript saved to /tmp/complete_manuscript.txt\")\n",
    "    \n",
    "    generate_complete_button.on_click(on_generate_complete_clicked)\n",
    "    \n",
    "    # Layout\n",
    "    interface = widgets.VBox([\n",
    "        widgets.HTML(\"<h3>üìÑ Complete Manuscript Generation</h3>\"),\n",
    "        widgets.HBox([generate_complete_button, export_format]),\n",
    "        complete_output\n",
    "    ])\n",
    "    \n",
    "    return interface\n",
    "\n",
    "# Create and display interface\n",
    "complete_interface = create_complete_manuscript_interface()\n",
    "display(complete_interface)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Example Usage and Workflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example workflow demonstration with referee reports\n",
    "def demonstrate_workflow():\n",
    "    \"\"\"Demonstrate the complete manuscript review workflow including referee reports\"\"\"\n",
    "    \n",
    "    print(\"üéØ DENARIO MANUSCRIPT REVIEW WORKFLOW DEMONSTRATION\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Step 1: Create a sample incomplete manuscript\n",
    "    sample_manuscript = \"\"\"\n",
    "    \\\\documentclass{article}\n",
    "    \\\\begin{document}\n",
    "    \n",
    "    \\\\title{Sample Research Paper}\n",
    "    \\\\author{Researcher}\n",
    "    \\\\maketitle\n",
    "    \n",
    "    \\\\abstract{This paper presents a novel approach to machine learning.}\n",
    "    \n",
    "    \\\\section{Introduction}\n",
    "    Machine learning has become increasingly important in recent years.\n",
    "    \n",
    "    \\\\section{Methods}\n",
    "    We used a neural network approach. The equation is: $E = mc^2$\n",
    "    \n",
    "    \\\\section{Results}\n",
    "    [Results section is incomplete]\n",
    "    \n",
    "    \\\\section{Discussion}\n",
    "    [Discussion section is missing]\n",
    "    \n",
    "    \\\\section{Conclusion}\n",
    "    [Conclusion section is missing]\n",
    "    \n",
    "    \\\\end{document}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Save sample manuscript\n",
    "    with open('/tmp/sample_manuscript.tex', 'w') as f:\n",
    "        f.write(sample_manuscript)\n",
    "    \n",
    "    print(\"üìù Step 1: Sample manuscript created\")\n",
    "    print(\"   - Contains incomplete Results section\")\n",
    "    print(\"   - Missing Discussion and Conclusion sections\")\n",
    "    print(\"   - Has some mathematical content to verify\")\n",
    "    \n",
    "    # Step 2: Load and analyze\n",
    "    print(\"\\nüîç Step 2: Analyzing manuscript...\")\n",
    "    if enhanced_reviewer.load_manuscript('/tmp/sample_manuscript.tex'):\n",
    "        report = enhanced_reviewer.generate_report()\n",
    "        \n",
    "        print(f\"   - Found {len(report['sections'])} sections\")\n",
    "        print(f\"   - Identified {report['total_issues']} issues\")\n",
    "        print(f\"   - Found {report['citations']['total_citations']} citations\")\n",
    "        print(f\"   - Detected {report['mathematics']['equations']} equations\")\n",
    "    \n",
    "    # Step 3: Load referee report\n",
    "    print(\"\\nüìã Step 3: Loading referee report...\")\n",
    "    sample_referee_report = \"\"\"\n",
    "    RECOMMENDATION: Major Revision\n",
    "    \n",
    "    Major Issues:\n",
    "    1. The Methods section lacks sufficient detail about the experimental setup and data preprocessing steps.\n",
    "    2. The Results section is incomplete and needs statistical analysis and proper visualization.\n",
    "    3. Missing discussion of limitations and potential biases in the methodology.\n",
    "    \n",
    "    Minor Issues:\n",
    "    1. Fix typo in line 12: \"authro\" should be \"author\"\n",
    "    2. Add more recent references to the Introduction section.\n",
    "    3. Improve figure captions for better clarity.\n",
    "    \n",
    "    Suggestions:\n",
    "    1. Consider adding a comparison with existing methods in the Discussion section.\n",
    "    2. The conclusion could be more comprehensive and include future work directions.\n",
    "    \"\"\"\n",
    "    \n",
    "    if referee_reviewer.load_referee_report(sample_referee_report):\n",
    "        print(\"   ‚úÖ Referee report loaded successfully\")\n",
    "        print(\"   üìä Parsed comments and identified priority issues\")\n",
    "    else:\n",
    "        print(\"   ‚ùå Failed to load referee report\")\n",
    "    \n",
    "    # Step 4: Generate responses to referee comments\n",
    "    print(\"\\nüîÑ Step 4: Generating responses to referee comments...\")\n",
    "    \n",
    "    # Generate responses for sections with comments\n",
    "    methods_response = referee_reviewer.generate_referee_response('Methods')\n",
    "    results_response = referee_reviewer.generate_referee_response('Results')\n",
    "    discussion_response = referee_reviewer.generate_referee_response('Discussion')\n",
    "    \n",
    "    print(\"   ‚úÖ Generated responses for Methods section\")\n",
    "    print(\"   ‚úÖ Generated responses for Results section\")\n",
    "    print(\"   ‚úÖ Generated responses for Discussion section\")\n",
    "    \n",
    "    # Step 5: Generate missing content\n",
    "    print(\"\\nüîÑ Step 5: Generating missing content...\")\n",
    "    \n",
    "    # Generate Results section\n",
    "    results_content = enhanced_reviewer.generate_missing_content(\n",
    "        'Results', \n",
    "        'Machine learning neural network performance metrics'\n",
    "    )\n",
    "    \n",
    "    # Generate Discussion section\n",
    "    discussion_content = enhanced_reviewer.generate_missing_content(\n",
    "        'Discussion', \n",
    "        'Implications of neural network results for machine learning'\n",
    "    )\n",
    "    \n",
    "    # Generate Conclusion section\n",
    "    conclusion_content = enhanced_reviewer.generate_missing_content(\n",
    "        'Conclusion', \n",
    "        'Summary of findings and future work'\n",
    "    )\n",
    "    \n",
    "    print(\"   ‚úÖ Generated Results section\")\n",
    "    print(\"   ‚úÖ Generated Discussion section\") \n",
    "    print(\"   ‚úÖ Generated Conclusion section\")\n",
    "    \n",
    "    # Step 6: Verify mathematics\n",
    "    print(\"\\nüßÆ Step 6: Verifying mathematics...\")\n",
    "    math_result = enhanced_reviewer.verify_mathematics(\"$E = mc^2$\")\n",
    "    print(f\"   - Mathematics verification: {math_result['status']}\")\n",
    "    \n",
    "    # Step 7: Generate complete manuscript\n",
    "    print(\"\\nüìÑ Step 7: Generating complete manuscript...\")\n",
    "    complete_manuscript = enhanced_reviewer.generate_complete_manuscript()\n",
    "    \n",
    "    if complete_manuscript:\n",
    "        print(\"   ‚úÖ Complete manuscript generated with all sections\")\n",
    "        print(f\"   - Total sections: {len(complete_manuscript)}\")\n",
    "        \n",
    "        # Show summary\n",
    "        print(\"\\nüìä MANUSCRIPT SUMMARY:\")\n",
    "        for section, content in complete_manuscript.items():\n",
    "            word_count = len(content.split()) if content else 0\n",
    "            print(f\"   - {section}: {word_count} words\")\n",
    "    \n",
    "    print(\"\\nüéâ Workflow demonstration completed!\")\n",
    "    print(\"   The manuscript has been analyzed, enhanced, and completed\")\n",
    "    print(\"   with proper citations, verified mathematics, and referee responses.\")\n",
    "\n",
    "# Run demonstration\n",
    "demonstrate_workflow()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary and Next Steps\n",
    "\n",
    "This notebook demonstrates how Denario can be used for comprehensive manuscript review and completion. The system provides:\n",
    "\n",
    "### ‚úÖ **Key Capabilities Delivered:**\n",
    "\n",
    "1. **Section Completeness Analysis** - Identifies missing or incomplete sections\n",
    "2. **Referee Report Parsing** - Automatically parses and prioritizes reviewer comments\n",
    "3. **Referee Response Generation** - Generates content that addresses specific reviewer comments\n",
    "4. **Content Generation** - Uses Denario's AI agents to generate missing content\n",
    "5. **Citation Integration** - Automatically adds relevant in-text citations\n",
    "6. **Mathematical Verification** - Checks and verifies mathematical derivations\n",
    "7. **Interactive Interface** - User-friendly widgets for all operations\n",
    "8. **Export Functionality** - Generate complete manuscripts in multiple formats\n",
    "\n",
    "### üéØ **Addresses Your Original Request:**\n",
    "\n",
    "- ‚úÖ **Identify incomplete sections** - Automated analysis detects missing content\n",
    "- ‚úÖ **Construct text with in-text citations** - AI-generated content with proper citations\n",
    "- ‚úÖ **Verify mathematics/calculations** - Mathematical verification system\n",
    "- ‚úÖ **Natural flow within manuscript** - Context-aware content generation\n",
    "- ‚úÖ **Address referee comments** - Systematic response to reviewer feedback\n",
    "- ‚úÖ **Priority-based responses** - High/Medium/Low priority comment handling\n",
    "\n",
    "### üöÄ **Next Steps:**\n",
    "\n",
    "1. **Upload your actual manuscript** using the file upload widget\n",
    "2. **Upload referee report** (if available) using the referee report interface\n",
    "3. **Run the analysis** to identify specific issues and parse referee comments\n",
    "4. **Generate responses to referee comments** using the automated response system\n",
    "5. **Generate missing content** section by section\n",
    "6. **Verify all mathematics** using the verification interface\n",
    "7. **Export the complete manuscript** in your preferred format\n",
    "\n",
    "### üí° **Tips for Best Results:**\n",
    "\n",
    "- **Referee Reports**: Use clear section references (e.g., \"Methods section, lines 45-67\")\n",
    "- **Priority Issues**: Focus on HIGH priority comments first, then MEDIUM, then LOW\n",
    "- **Content Generation**: Provide clear context when generating content\n",
    "- **Review Process**: Review generated content before finalizing\n",
    "- **Mathematics**: Use the mathematical verification for all equations\n",
    "- **Export Format**: Export in LaTeX format for academic papers\n",
    "- **Save Work**: Save your work frequently\n",
    "\n",
    "**Ready to review your manuscript? Start by uploading your file above!** üìö\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
